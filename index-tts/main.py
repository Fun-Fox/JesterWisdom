import os
import pandas as pd
import asyncio

from tts import init_tts
from asr import generate_srt, get_whisper_model
from loguru import logger
from doubao_rpa import image_to_image_start

root_dir = os.path.dirname(os.path.abspath(__file__))


def read_excel_data(excel_path):
    """
    è¯»å– Excel æ–‡ä»¶ä¸­çš„å†…å®¹ã€‚

    :param excel_path: Excel æ–‡ä»¶çš„è·¯å¾„
    :return: åŒ…å« "è‹±æ–‡ç¿»è¯‘" å’Œ "ä¸­æ–‡å¥å­" çš„ DataFrame
    """
    df = pd.read_excel(excel_path)
    return df[["è‹±æ–‡ç¿»è¯‘", "ä¸­æ–‡å¥å­"]]


def main():
    tts, i18n = init_tts()
    # è¯»å– Excel æ•°æ®
    excel_path = os.path.join(root_dir, "assets", "é¸¡æ±¤.xlsx")
    df = read_excel_data(excel_path)

    start_row = 0
    end_row = 20

    for idx, row in df[start_row:end_row].iterrows():

        english_text = row["è‹±æ–‡ç¿»è¯‘"]
        # english_text = row["ä¸­æ–‡å¥å­"]
        chinese_text = row["ä¸­æ–‡å¥å­"]

        # åˆ›å»ºä»¥è¡Œå·å‘½åçš„è¾“å‡ºç›®å½•
        output_dir = os.path.join(root_dir, "output", f"row_{idx + 1}")
        os.makedirs(output_dir, exist_ok=True)

        # TTS ç”ŸæˆéŸ³é¢‘
        speaker_audio_path = os.path.join(root_dir, "assets", "å°ä¸‘éŸ³é¢‘-1.MP3")
        tts_audio_tmp_output_path = os.path.join(output_dir, f"tts_audio_{idx + 1}.wav")
        tts.infer_fast(speaker_audio_path, english_text, tts_audio_tmp_output_path)

        # å›¾åƒç”Ÿæˆ
        image_nums = 6
        prompt = f"""å‚è€ƒè¿™ä¸ªå°ä¸‘è§’è‰²ä¸»ä½“å›¾ç‰‡ï¼Œç”Ÿæˆ{image_nums}å¼ 16:9çš„å›¾ã€‚
        - è§’è‰²ä¸»ä½“é•œå¤´ç”±ï¼šå…¨æ™¯ â†’ ä¸­æ™¯-> ä¸­è¿‘æ™¯ â†’ è¿‘æ™¯ â†’ç‰¹å†™->  æç‰¹å†™
        - äººç‰©ä¿æŒä¸€è‡´æ€§
        - åœºæ™¯ä¿æŒç»Ÿä¸€
        - é¢œè‰²ä¸ºé»‘ç™½è‰²
        - äººç‰©æ˜¯ç¾å›½äºº
        - å›¾ç‰‡ä¸­ä¸å…è®¸å‡ºç°æ–‡å­—
        é‡ç‚¹æ³¨æ„éœ€è¦ç»“åˆä»¥ä¸‹å†…å®¹æ„å¢ƒï¼š
        '{chinese_text}'
        """
        # reference_image_path = os.path.join(root_dir, "assets", "å°ä¸‘ä¸»ä½“å‚è€ƒå›¾.png")
        reference_image_path = os.path.join(root_dir, "assets", "å°ä¸‘ä¸»ä½“å‚è€ƒå›¾-2.jpg")
        asyncio.run(
            image_to_image_start(logger, [reference_image_path], prompt, output_dir, image_nums, sleep_time=35000,
                                 enable_download_image=True)
        )

        # Whisper è½¬å½•éŸ³é¢‘å¹¶ç”Ÿæˆ SRT
        whisper = get_whisper_model()
        segments, _ = whisper.transcribe(tts_audio_tmp_output_path, beam_size=7, language="en",
                                         condition_on_previous_text=False, word_timestamps=True)
        output_srt_path = os.path.join(output_dir, "output.srt")
        generate_srt(segments, output_srt_path)

        print(f"ğŸ”Š å¤„ç†éŸ³é¢‘: {tts_audio_tmp_output_path}")


if __name__ == "__main__":
    main()
